# ğŸ¤– Intelligent Document Assistant

A production-ready AI application built with Next.js 15, TypeScript, and Google Gemini that demonstrates advanced RAG (Retrieval-Augmented Generation) implementation for document processing and intelligent question answering.

## ğŸ¯ **Project Purpose**

This project is created for **educational and portfolio purposes** to demonstrate:
- Advanced AI engineering skills with LangChain.js and Google Gemini
- Full-stack development with modern technologies (Next.js 15, TypeScript)
- Production-ready application architecture and best practices
- Complete RAG pipeline implementation with vector similarity search
- Professional software development practices and documentation

## âš ï¸ **Important Notice**

**This project is for educational and portfolio use only. Commercial use is prohibited without explicit permission.**

## ğŸš€ **Key Features**

### **Core Functionality**
- **ğŸ“„ Document Upload**: Support for PDF, TXT, DOCX, and Markdown files
- **ğŸ¤– AI-Powered Q&A**: Ask questions about uploaded documents using Google Gemini
- **ğŸ“š Source Citations**: Get answers with references to specific document sections
- **ğŸ—‚ï¸ Document Management**: View, filter, and manage uploaded documents
- **âš¡ Real-time Processing**: Live status updates during document processing

### **Technical Excellence**
- **ğŸ”’ Type-Safe**: Full TypeScript implementation with strict mode
- **ğŸ“± Responsive Design**: Mobile-first approach with Tailwind CSS
- **ğŸ›¡ï¸ Error Handling**: Comprehensive error handling with retry logic
- **âš¡ Performance**: Optimized with proper loading states and caching
- **ğŸ” Security**: Input validation and file type restrictions

### **AI & RAG Implementation**
- **ğŸ§  Smart Chunking**: Intelligent document splitting with sentence boundary detection
- **ğŸ” Vector Search**: Cosine similarity search for relevant content retrieval
- **ğŸ¯ Embedding Generation**: Google Gemini embeddings for semantic understanding
- **ğŸ“Š Relevance Scoring**: Confidence and relevance metrics for answers
- **ğŸ”„ Complete RAG Pipeline**: Query â†’ Embedding â†’ Retrieval â†’ Generation â†’ Citation

## ğŸ› ï¸ **Tech Stack**

### **Frontend**
- **Next.js 15** with App Router
- **TypeScript** (strict mode)
- **Tailwind CSS** for styling
- **React 19** with modern hooks

### **Backend**
- **Next.js API Routes** for backend logic
- **LangChain.js** for AI functionality
- **Google Gemini** models (text-embedding-004, gemini-1.5-flash)
- **Prisma ORM** with SQLite database
- **Zod** for validation

### **AI & ML**
- **RAG Architecture** with document chunking
- **Vector Embeddings** for semantic search
- **Cosine Similarity** for content retrieval
- **Context-Aware Generation** with source citations

### **Development & Testing**
- **Jest** for unit testing
- **Cypress** for E2E testing
- **ESLint** for code quality
- **TypeScript** for type safety

## ğŸ“ **Project Architecture**

```
document-assistant-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # API routes
â”‚   â”‚   â”œâ”€â”€ health/             # Health check endpoint
â”‚   â”‚   â”œâ”€â”€ upload/             # File upload endpoint
â”‚   â”‚   â”œâ”€â”€ process/            # Document processing endpoint
â”‚   â”‚   â”œâ”€â”€ query/              # Query processing endpoint
â”‚   â”‚   â””â”€â”€ documents/          # Document management endpoint
â”‚   â”œâ”€â”€ client/                 # Client-side components
â”‚   â””â”€â”€ layout.tsx              # Root layout
â”œâ”€â”€ components/                 # Reusable UI components
â”‚   â”œâ”€â”€ FileUpload.tsx          # Drag-and-drop file upload
â”‚   â”œâ”€â”€ DocumentList.tsx        # Document management interface
â”‚   â”œâ”€â”€ QueryInterface.tsx     # Question input interface
â”‚   â”œâ”€â”€ QueryResults.tsx        # AI response display
â”‚   â””â”€â”€ ...                     # Other UI components
â”œâ”€â”€ lib/                        # Core business logic
â”‚   â”œâ”€â”€ types.ts                # TypeScript type definitions
â”‚   â”œâ”€â”€ utils.ts                # Utility functions
â”‚   â”œâ”€â”€ ai-services.ts          # AI service integration
â”‚   â”œâ”€â”€ database.ts             # Database service layer
â”‚   â”œâ”€â”€ chunking.ts             # Document chunking service
â”‚   â”œâ”€â”€ config.ts               # Application configuration
â”‚   â””â”€â”€ error-handling.ts       # Error handling utilities
â”œâ”€â”€ prisma/                     # Database schema and migrations
â”‚   â””â”€â”€ schema.prisma           # Database models
â”œâ”€â”€ __tests__/                  # Unit tests
â”œâ”€â”€ cypress/                    # E2E tests
â””â”€â”€ docs/                       # Documentation
```

## ğŸš€ **Getting Started**

### **Prerequisites**
- Node.js 18+ 
- npm or yarn
- Google AI API key

### **Installation**

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd document-assistant-ai
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   cp env.example .env.local
   ```
   
   Edit `.env.local` and add your Google API key:
   ```env
   GOOGLE_API_KEY=your_google_api_key_here
   DATABASE_URL="file:./dev.db"
   ```

4. **Set up the database**
   ```bash
   npx prisma generate
   npx prisma db push
   ```

5. **Get Google AI API Key**
   - Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Create a new API key
   - Copy the key to your `.env.local` file

6. **Run the development server**
   ```bash
   npm run dev
   ```

7. **Open your browser**
   Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“– **Usage**

### **1. Upload Documents**
- Click on the "Upload Documents" tab
- Drag and drop files or click "browse files"
- Supported formats: PDF, TXT, DOCX, MD
- Maximum file size: 10MB

### **2. Manage Documents**
- View uploaded documents in the "My Documents" tab
- Filter by status (uploading, processing, processed, error)
- Select specific documents for targeted queries

### **3. Ask Questions**
- Switch to the "Ask Questions" tab
- Type your question in the text area
- Use example questions or create your own
- Get AI-powered answers with source citations

## ğŸ”§ **API Endpoints**

### **Health Check**
```http
GET /api/health
```
Returns the status of all services (AI, Database, File Storage).

### **File Upload**
```http
POST /api/upload
Content-Type: multipart/form-data

file: [File]
```
Uploads and processes a document file with real text extraction.

### **Document Processing**
```http
POST /api/process
Content-Type: application/json

{
  "documentId": "string",
  "forceReprocess": boolean
}
```
Processes a document and creates searchable chunks with embeddings.

### **Query Processing**
```http
POST /api/query
Content-Type: application/json

{
  "question": "string",
  "documentIds": ["string"],
  "maxResults": number,
  "includeSources": boolean
}
```
Processes a user query and returns AI-generated answers with sources.

### **Document Management**
```http
GET /api/documents
```
Retrieves all uploaded documents with their processing status.

## ğŸ§ª **Testing**

### **Unit Tests**
```bash
npm run test
```

### **Tests with Coverage**
```bash
npm run test:coverage
```

### **E2E Tests**
```bash
npm run test:e2e
```

### **All Tests**
```bash
npm run test:all
```

## ğŸš€ **Deployment**

### **Vercel (Recommended)**
1. Push your code to GitHub
2. Connect your repository to Vercel
3. Add environment variables in Vercel dashboard:
   - `GOOGLE_API_KEY`: Your Google AI API key
   - `DATABASE_URL`: Your database connection string
4. Deploy!

### **Manual Deployment**
```bash
npm run build
npm start
```

## ğŸ”’ **Environment Variables**

| Variable | Description | Required | Example |
|----------|-------------|----------|---------|
| `GOOGLE_API_KEY` | Google AI API key | Yes | `AIzaSy...` |
| `DATABASE_URL` | Database connection string | Yes | `file:./dev.db` |
| `NEXT_PUBLIC_APP_NAME` | Application name | No | `Intelligent Document Assistant` |
| `NEXT_PUBLIC_MAX_FILE_SIZE` | Max file size (bytes) | No | `10485760` |
| `NEXT_PUBLIC_ALLOWED_FILE_TYPES` | Allowed file types | No | `pdf,txt,docx,md` |

## ğŸ—ï¸ **Architecture Deep Dive**

### **RAG Pipeline Implementation**

1. **Document Upload & Processing**
   ```
   File Upload â†’ Text Extraction â†’ Document Chunking â†’ Embedding Generation â†’ Database Storage
   ```

2. **Query Processing**
   ```
   User Query â†’ Query Embedding â†’ Vector Similarity Search â†’ Context Retrieval â†’ AI Response Generation
   ```

3. **Vector Similarity Search**
   - Cosine similarity calculation between query and document embeddings
   - Relevance scoring and ranking
   - Context window management

### **Database Schema**
- **Documents**: Store uploaded files and metadata
- **DocumentChunks**: Store processed chunks with embeddings
- **Queries**: Store user queries and responses
- **QuerySources**: Track which chunks were used for answers

### **Error Handling & Resilience**
- Exponential backoff retry logic
- Comprehensive error boundaries
- Graceful degradation
- User-friendly error messages

## ğŸ“Š **Performance Features**

### **Optimization Strategies**
- **Lazy Loading**: Components loaded on demand
- **Caching**: API responses cached where appropriate
- **Chunking**: Large documents processed in chunks
- **Debouncing**: Search inputs debounced to reduce API calls
- **Vector Search**: Efficient similarity calculations

### **Monitoring & Observability**
- **Health Checks**: Regular service health monitoring
- **Error Tracking**: Comprehensive error logging
- **Performance Metrics**: Response time tracking
- **Processing Status**: Real-time status updates

## ğŸ”§ **Customization**

### **Adding New File Types**
1. Update `DocumentType` in `lib/types.ts`
2. Add extraction logic in `app/api/upload/route.ts`
3. Update validation in `components/FileUpload.tsx`

### **Modifying AI Behavior**
1. Adjust parameters in `lib/ai-services.ts`
2. Update prompts for different response styles
3. Modify chunking strategy in `lib/chunking.ts`

### **Styling Changes**
1. Update Tailwind classes in components
2. Modify color scheme in `tailwind.config.js`
3. Add custom CSS for specific components

## ğŸ¯ **Key Technical Achievements**

### **AI Engineering**
- âœ… Complete RAG pipeline implementation
- âœ… Vector similarity search with cosine similarity
- âœ… Intelligent document chunking with sentence boundaries
- âœ… Context-aware AI responses with source citations
- âœ… Embedding generation and storage

### **Full-Stack Development**
- âœ… Type-safe API development with TypeScript
- âœ… Modern React patterns with hooks and context
- âœ… Database design and ORM integration
- âœ… File processing and validation
- âœ… Error handling and user experience

### **Production Readiness**
- âœ… Comprehensive testing suite (unit + E2E)
- âœ… Error handling and retry logic
- âœ… Performance optimization
- âœ… Security considerations
- âœ… Professional documentation

## ğŸ“ˆ **Performance Metrics**

- **Document Processing**: 5-15 seconds depending on file size
- **Query Response**: 2-5 seconds with context retrieval
- **Vector Search**: Sub-second similarity calculations
- **UI Responsiveness**: <100ms for user interactions

## ğŸ”® **Future Enhancements**

- **Multi-language Support**: Process documents in different languages
- **Advanced Chunking**: Semantic chunking based on content structure
- **Vector Database**: Integration with Pinecone or Weaviate
- **User Authentication**: Multi-user support with document privacy
- **API Rate Limiting**: Production-grade rate limiting
- **Caching Layer**: Redis integration for improved performance

## ğŸ¤ **Contributing**

This project is currently **not accepting contributions**. See [CONTRIBUTING.md](CONTRIBUTING.md) for more information.

## ğŸ“„ **License**

This project is licensed under the MIT License with commercial use restrictions. See [LICENSE](LICENSE) file for details.

## ğŸ“ **Contact**

For questions about this project or professional opportunities, please reach out through GitHub Issues or LinkedIn.

---

**Built with â¤ï¸ for AI Engineer Portfolio**

**âš ï¸ Commercial Use Prohibited** - This project is for educational and portfolio purposes only.